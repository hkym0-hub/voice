# =========================================================
# WaveSketch: Emotion Colors + Audio-driven Thickness
# =========================================================

import io
import random
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import librosa
import colorsys

# ---------------------------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="WaveSketch - Emotion Colors + Audio Thickness",
    page_icon="ğŸ§",
    layout="wide"
)

# ----------------------- (1) ì•ˆë‚´ í…ìŠ¤íŠ¸ -----------------------
st.title("ğŸ§ WaveSketch: Emotion Colors + Audio-Driven Line Thickness")
st.write(
    "Upload a short **WAV or MP3** file. "
    "Your voice generates a drawing where **emotion controls the colors** "
    "and **sound dynamics control the line thickness**."
)
st.caption("âš ï¸ m4aëŠ” ì„œë²„í™˜ê²½ ë¬¸ì œë¡œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. WAV ë˜ëŠ” MP3 ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")


# ---------------------------------------------------------
# Emotion â†’ Color Palette (Hue ranges)
# ---------------------------------------------------------
def get_emotion_hue_range(emotion):
    """
    ê°ì •ë§ˆë‹¤ ê³ ìœ í•œ ìƒ‰ì¡°(hue) ë²”ìœ„ë¥¼ ë°˜í™˜.
    ê·¸ ë²”ìœ„ ì•ˆì—ì„œ ëœë¤í•˜ê²Œ ìƒ‰ì„ ìƒì„±í•¨.
    """
    table = {
        "joy":      (0.10, 0.20),   # yellow â†’ orange
        "sadness":  (0.55, 0.65),   # blue â†’ deep blue
        "anger":    (0.95, 1.00),   # red
        "fear":     (0.68, 0.75),   # purple
        "surprise": (0.30, 0.40),   # green â†’ mint
        "neutral":  (0.00, 1.00),   # full spectrum
    }
    return table.get(emotion, (0.00, 1.00))


# ---------------------------------------------------------
# Utility: Render Matplotlib â†’ streamlit image
# ---------------------------------------------------------
def render_figure_to_bytes(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=200, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return buf


# ---------------------------------------------------------
# AUDIO ANALYSIS
# ---------------------------------------------------------
def analyze_audio(uploaded_file, target_points=1200):
    uploaded_file.seek(0)
    y, sr = librosa.load(uploaded_file, sr=None, mono=True)

    if len(y) > 10 * sr:  # ìµœëŒ€ 10ì´ˆê¹Œì§€ë§Œ ë¶„ì„
        y = y[:10 * sr]

    idx = np.linspace(0, len(y) - 1, target_points, dtype=int)
    y_ds = y[idx]  # downsample
    t = np.linspace(0, 1, len(y_ds))

    rms = librosa.feature.rms(y=y)[0]
    zcr = librosa.feature.zero_crossing_rate(y=y)[0]

    # ìŒì •(pitch)ì€ ìƒ‰ìƒ ë³€í™”ì— ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ featureë¡œ ì¶œë ¥
    try:
        pitches = librosa.yin(y, fmin=80, fmax=1000)
        pitch_mean = float(np.nanmean(pitches))
    except Exception:
        pitch_mean = 0.0

    features = {
        "sr": sr,
        "rms": float(np.mean(rms)),
        "zcr": float(np.mean(zcr)),
        "pitch": pitch_mean,
    }

    return t, y_ds, features


# ---------------------------------------------------------
# COLOR ENGINE (Emotion â†’ Hue range)
# ---------------------------------------------------------
def get_emotion_color(emotion):
    hue_min, hue_max = get_emotion_hue_range(emotion)
    h = random.uniform(hue_min, hue_max)

    s = random.uniform(0.6, 1.0)  # vivid saturation
    v = random.uniform(0.7, 1.0)  # bright value

    r, g, b = colorsys.hsv_to_rgb(h, s, v)
    return (float(r), float(g), float(b))


# ---------------------------------------------------------
# THICKNESS ENGINE (Audio-driven)
# ---------------------------------------------------------
def compute_line_thickness(amplitude, rms, zcr):
    """
    ì†Œë¦¬ ì„¸ê¸°(amplitude, rms, zcr)ì— ë”°ë¼ ì„  êµµê¸° ë³€í™”.
    ê°ì •ì€ êµµê¸°ì— ì˜í–¥ì„ ì£¼ì§€ ì•ŠìŒ.
    """
    amp_factor = abs(amplitude) * 4
    rms_factor = rms * 30
    zcr_factor = zcr * 8

    thickness = 1.0 + amp_factor + rms_factor + zcr_factor
    return max(0.5, thickness)  # ìµœì†Œ êµµê¸° ë³´ì¥


# ---------------------------------------------------------
# Drawing: Line Style Only
# ---------------------------------------------------------
def draw_line_style(t, y, feats, emotion, seed):
    random.seed(seed)
    np.random.seed(seed)

    amp = y / (np.max(np.abs(y)) + 1e-8)

    rms = feats["rms"]
    zcr = feats["zcr"]

    fig, ax = plt.subplots(figsize=(6, 8))
    ax.axis("off")
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)

    base_y = 0.5 + amp * 0.35  # íŒŒí˜• ë³€í™˜
    n_layers = 8  # ê³ ì •ëœ ë ˆì´ì–´ ìˆ˜

    for layer in range(n_layers):
        offset = (layer - (n_layers - 1) / 2) * 0.03
        y_line = base_y + offset

        for i in range(len(t) - 1):
            color = get_emotion_color(emotion)

            lw = compute_line_thickness(
                amplitude=amp[i],
                rms=rms,
                zcr=zcr
            )

            ax.plot(
                t[i:i+2], y_line[i:i+2],
                color=color,
                linewidth=lw,
                alpha=0.7,
            )

    return render_figure_to_bytes(fig)


# ---------------------------------------------------------
# SIDEBAR UI
# ---------------------------------------------------------
st.sidebar.header("Drawing Controls")

emotion_label = st.sidebar.selectbox(
    "Emotion (Affects Colors)",
    ["neutral", "joy", "sadness", "anger", "fear", "surprise"]
)

seed = st.sidebar.slider("Random Seed", 0, 9999, 42)

# AssemblyAI API ë¯¸ì‚¬ìš©ì´ì§€ë§Œ ì…ë ¥ì°½ ìœ ì§€
st.sidebar.header("AssemblyAI API (Optional)")
api_key = st.sidebar.text_input(
    "AssemblyAI API Key",
    placeholder="Enter your API key...",
    type="password"
)


# ---------------------------------------------------------
# 1ï¸âƒ£ Upload Audio
# ---------------------------------------------------------
st.subheader("1ï¸âƒ£ Upload Audio")
uploaded_file = st.file_uploader("Upload WAV or MP3", type=["wav", "mp3"])

if not uploaded_file:
    st.stop()

st.audio(uploaded_file)

t, y_ds, feats = analyze_audio(uploaded_file)


# ---------------------------------------------------------
# 2ï¸âƒ£ Extracted Audio Features
# ---------------------------------------------------------
st.subheader("2ï¸âƒ£ Extracted Audio Features")
st.json(feats)


# ---------------------------------------------------------
# 3ï¸âƒ£ Generated Drawing
# ---------------------------------------------------------
st.subheader("3ï¸âƒ£ Generated Drawing")

img_buf = draw_line_style(t, y_ds, feats, emotion_label, seed)

st.image(
    img_buf,
    caption=f"Line Style â€“ Emotion Colors + Audio Thickness",
    use_container_width=True
)


# ---------------------------------------------------------
# 4ï¸âƒ£ Emotion â†’ Color Guide
# ---------------------------------------------------------
st.markdown("## ğŸ¨ Emotion-Based Color Guide")
st.markdown("""
Each emotion generates colors from a **unique hue range**, giving each drawing a distinct emotional tone.

### Emotion â†’ Color Mapping  
- **joy** â†’ Yellow / Orange spectrum  
- **sadness** â†’ Blue / Deep blue  
- **anger** â†’ Red / Crimson  
- **fear** â†’ Purple / Dark violet  
- **surprise** â†’ Green / Mint  
- **neutral** â†’ All colors (full spectrum, softer saturation)

Emotion affects **only color**, not thickness.
""")


# ---------------------------------------------------------
# 5ï¸âƒ£ Audio â†’ Line Thickness Guide
# ---------------------------------------------------------
st.markdown("## ğŸ§µ Audio-Based Line Thickness Guide")
st.markdown("""
The **thickness** of each line segment is determined by audio dynamics:

### Thickness Factors  
- **Amplitude** (momentary volume) â†’ stronger â†’ thicker  
- **RMS Energy** (overall loudness) â†’ higher â†’ thicker  
- **ZCR** (noisiness/consonants) â†’ higher â†’ slightly thicker  

So the artwork visually reflects how **intense or calm** your voice was.
""")
