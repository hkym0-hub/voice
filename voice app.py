# =========================================================
# WaveSketch: Multi-Color Drawing from Sound Waves
# =========================================================

import io
import random
import numpy as np
import streamlit as st
import matplotlib.pyplot as plt
import librosa
import colorsys

# ---------------------------------------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="WaveSketch - Multi-Color Sound Drawings",
    page_icon="ðŸŽ§",
    layout="wide"
)

# ----------------------- (1) ì•ˆë‚´ í…ìŠ¤íŠ¸ -----------------------
st.title("ðŸŽ§ WaveSketch: Multi-Color Sound Drawings")
st.write(
    "Upload a short **WAV or MP3** file. "
    "Your voice becomes a multi-color drawing based on **amplitude, pitch, energy, and rhythm (ZCR)**."
)
st.caption("âš ï¸ m4aëŠ” ì„œë²„í™˜ê²½ ë¬¸ì œë¡œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. WAV ë˜ëŠ” MP3ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")


# ---------------------------------------------------------
# Emotion â†’ Line Thickness Mapping
# ---------------------------------------------------------
def get_emotion_thickness_multiplier(emotion):
    # ê°ì •ë³„ ì°¨ì´ë¥¼ ë” ê·¹ì ìœ¼ë¡œ í‚¤ìš´ ë²„ì „
    table = {
        "joy": 1.8,      # ë°ê³  ë‘êº¼ì›€
        "anger": 2.3,    # ê°€ìž¥ ê°•í•˜ê³  ë‘êº¼ì›€
        "surprise": 1.4, # ì‚´ì§ ë‘êº¼ì›€
        "neutral": 1.0,  # ê¸°ì¤€
        "fear": 0.6,     # ì–‡ê³  ì•½í•¨
        "sadness": 0.4   # ê°€ìž¥ ì–‡ê³  ì—¬ë¦¼
    }
    return table.get(emotion, 1.0)


# ---------------------------------------------------------
# Utility
# ---------------------------------------------------------
def render_figure_to_bytes(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format="png", dpi=200, bbox_inches="tight")
    buf.seek(0)
    plt.close(fig)
    return buf


# ---------------------------------------------------------
# AUDIO ANALYSIS
# ---------------------------------------------------------
def analyze_audio(uploaded_file, target_points=1200):
    uploaded_file.seek(0)
    y, sr = librosa.load(uploaded_file, sr=None, mono=True)

    if len(y) > 10 * sr:
        y = y[:10 * sr]

    idx = np.linspace(0, len(y) - 1, target_points, dtype=int)
    y_ds = y[idx]
    t = np.linspace(0, 1, len(y_ds))

    rms = librosa.feature.rms(y=y)[0]
    zcr = librosa.feature.zero_crossing_rate(y=y)[0]
    centroid = librosa.feature.spectral_centroid(y=y, sr=sr)[0]
    tempo, _ = librosa.beat.beat_track(y=y, sr=sr)

    try:
        pitches = librosa.yin(y, fmin=80, fmax=1000)
        pitch_mean = float(np.nanmean(pitches))
    except Exception:
        pitch_mean = 0.0

    features = {
        "sr": sr,
        "rms": float(np.mean(rms)),
        "zcr": float(np.mean(zcr)),
        "centroid": float(np.mean(centroid)),
        "tempo": float(tempo),
        "pitch": pitch_mean
    }

    return t, y_ds, features


# ---------------------------------------------------------
# COLOR ENGINE
# ---------------------------------------------------------
def get_dynamic_color(amplitude, pitch, energy, zcr):
    amp = np.clip(abs(amplitude), 0, 1)
    v = 0.2 + amp * 0.8  # brightness

    pitch_norm = np.clip((pitch - 80) / 270, 0, 1)

    if pitch_norm < 0.5:
        h = 0.6 - pitch_norm * 0.6
    else:
        h = 0.3 - (pitch_norm - 0.5) * 0.3

    h = h % 1.0

    energy_norm = np.clip(energy * 15, 0, 1)
    s = 0.2 + energy_norm * 0.8

    zcr_norm = np.clip(zcr * 50, 0, 1)
    h = (h + (random.random() - 0.5) * 0.2 * zcr_norm) % 1.0

    r, g, b = colorsys.hsv_to_rgb(h, s, v)
    return (float(r), float(g), float(b))


# ---------------------------------------------------------
# LINE STYLE (emotion + amplitude ë°˜ì˜)
# ---------------------------------------------------------
def draw_line_art(t, y, feats, complexity, seed, emotion_mul):
    random.seed(seed)
    np.random.seed(seed)

    amp = y / (np.max(np.abs(y)) + 1e-8)  # -1~1 â†’ -1~1
    base_y = 0.5 + amp * 0.35
    n_layers = 1 + complexity

    energy, pitch, zcr = feats["rms"], feats["pitch"], feats["zcr"]

    fig, ax = plt.subplots(figsize=(6, 8))
    ax.axis("off")
    ax.set_xlim(0, 1)
    ax.set_ylim(0, 1)

    # ê°ì • + ìŒëŸ‰ì— ë”°ë¼ ì„  ë‘ê»˜ê°€ í¬ê²Œ ë‹¬ë¼ì§€ë„ë¡ ì„¤ê³„
    base_width = 1.2  # neutral, quietì¼ ë•Œ ìµœì†Œ ë‘ê»˜ ê¸°ì¤€

    for layer in range(n_layers):
        offset = (layer - (n_layers - 1) / 2) * 0.03
        y_line = base_y + offset
        alpha = max(0.05, 0.35 - layer * 0.03)

        for i in range(len(t) - 1):
            color = get_dynamic_color(amp[i], pitch, energy, zcr)

            # amplitude(0~1) â†’ 1 ~ 4 ë°°
            local_amp = float(np.clip(abs(amp[i]), 0, 1))
            amp_factor = 1.0 + local_amp * 3.0

            # ìµœì¢… ì„  ë‘ê»˜ = ê¸°ë³¸ * ê°ì • * ìŒëŸ‰
            linewidth = base_width * emotion_mul * amp_factor

            ax.plot(
                t[i:i+2], y_line[i:i+2],
                color=color,
                linewidth=linewidth,
                alpha=alpha
            )

    return render_figure_to_bytes(fig)


# ---------------------------------------------------------
# SIDEBAR UI
# ---------------------------------------------------------
st.sidebar.header("Drawing Controls")

# ì´ì œ ìŠ¤íƒ€ì¼ ì„ íƒì€ ì—†ê³  ë³µìž¡ë„/ì‹œë“œë§Œ ì¡°ì ˆ
complexity = st.sidebar.slider("Complexity (Layer Count)", 1, 10, 5)
seed = st.sidebar.slider("Random Seed", 0, 9999, 42)

# â­ ê°ì • ì„ íƒ UI
emotion_label = st.sidebar.selectbox(
    "Emotion",
    ["neutral", "joy", "sadness", "anger", "fear", "surprise"]
)
emotion_mul = get_emotion_thickness_multiplier(emotion_label)

# â­ API KEY UI
st.sidebar.header("AssemblyAI API")
api_key = st.sidebar.text_input(
    "AssemblyAI API Key",
    placeholder="Enter your AssemblyAI API key...",
    type="password"
)

if api_key:
    st.sidebar.success("API Key registered âœ”")
else:
    st.sidebar.info("API Key not set (emotion auto-detection disabled)")


# ---------------------------------------------------------
# (2) Upload Audio
# ---------------------------------------------------------
st.subheader("1ï¸âƒ£ Upload Audio")

uploaded_file = st.file_uploader("Upload WAV or MP3", type=["wav", "mp3"])

if not uploaded_file:
    st.stop()

st.audio(uploaded_file)

with st.spinner("Analyzing audioâ€¦"):
    t, y_ds, feats = analyze_audio(uploaded_file)


# ---------------------------------------------------------
# (3) Extracted Audio Features
# ---------------------------------------------------------
st.subheader("2ï¸âƒ£ Extracted Audio Features")
st.json(feats)


# ---------------------------------------------------------
# (4) Generated Drawing
# ---------------------------------------------------------
st.subheader("3ï¸âƒ£ Generated Drawing")

img_buf = draw_line_art(t, y_ds, feats, complexity, seed, emotion_mul)

st.image(
    img_buf,
    caption=f"Line Style â€“ audio-driven multi-color drawing ({emotion_label})",
    use_container_width=True
)


# ---------------------------------------------------------
# (5) ðŸ§µ Emotion-Based Line Thickness Guide
# ---------------------------------------------------------
st.markdown("## ðŸ§µ Emotion-Based Line Thickness Guide")
st.markdown("""
Each emotion influences the **thickness of the lines** in the artwork.

### Emotion â†’ Thickness Mapping  
- **joy** â†’ much thicker, lively lines (~1.8Ã—)  
- **anger** â†’ the strongest and thickest strokes (~2.3Ã—)  
- **surprise** â†’ slightly thicker and sharper lines (~1.4Ã—)  
- **neutral** â†’ standard thickness (1.0Ã—)  
- **fear** â†’ thinner, more fragile lines (~0.6Ã—)  
- **sadness** â†’ the thinnest and most delicate strokes (~0.4Ã—)  

On top of this, **louder moments** in your voice make lines locally thicker,
while quieter parts stay almost thread-like.
""")


# ---------------------------------------------------------
# (6) ðŸŽ¨ Color Interpretation Guide
# ---------------------------------------------------------
st.markdown("## ðŸŽ¨ Color Interpretation Guide")
st.markdown("""
### ðŸŒ— Dark vs Bright Colors
Quiet parts â†’ darker  
Loud parts â†’ brighter  

### ðŸŒˆ Hue (Cool â†’ Warm)
Low pitch â†’ blue  
Mid pitch â†’ green/yellow  
High pitch â†’ orange/red  

### ðŸŽ¯ Saturation
High RMS â†’ vivid colors  
Low RMS â†’ soft pastel  

### ðŸŒ€ ZCR
Noisy sections â†’ color jitter  
""")
